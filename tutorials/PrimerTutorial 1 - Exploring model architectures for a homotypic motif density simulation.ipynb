{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APNfq3knhfZg"
   },
   "source": [
    "# How to train your DragoNN tutorial 1: \n",
    "## Exploring convolutional neural network (CNN) architectures for simulated genomic data\n",
    "\n",
    "This tutorial is a supplement to the DragoNN manuscript and follows figure 5 in the manuscript. \n",
    "\n",
    "This tutorial will take 20 - 30 minutes if executed on a GPU.\n",
    "\n",
    "## Outline<a name='outline'>\n",
    "<ol>\n",
    "    <li><a href=#1>How to use this tutorial</a></li>\n",
    "    <li><a href=#2>Review of patterns in transcription factor binding sites</a></li>\n",
    "    <li><a href=#3>Learning to localize homotypic motif density</a></li>\n",
    "    <li><a href=#4>Simulate training data with simdna</a></li>  \n",
    "    <li><a href=#4.5>Running dragonn on your own data: starting with FASTA files</a></li>\n",
    "    <li><a href=#5>Defining CNN architecture</a></li>\n",
    "    <li><a href=#6>Single layer, single filter model</a></li>\n",
    "    <li><a href=#7>Single layer, multiple filter model</a></li>\n",
    "    <li><a href=#8>Model Interpretation</a></li>    \n",
    "    <li><a href=#9>Multi-layer model</a></li>\n",
    "    <li><a href=#10>Regularized multi-layer model</a></li>\n",
    "    <li><a href=#11>Comparison of DragoNN to LSGKM </a></li>\n",
    "    <li><a href=#12>Further exploration</a></li>    \n",
    "    <li><a href=#13>Using DragoNN with your own non-simulated data</a></li>\n",
    "</ol>\n",
    "Github issues on the dragonn repository with feedback, questions, and discussion are always welcome.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NixF5bW3hfZg"
   },
   "source": [
    "## How to use this tutorial<a name='1'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "This tutorial utilizes a Jupyter/IPython Notebook - an interactive computational enviroment that combines live code, visualizations, and explanatory text. The notebook is organized into a series of cells. You can run the next cell by cliking the play button:\n",
    "![play button](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/play_button.png?raw=1)\n",
    "You can also run all cells in a series by clicking \"run all\" in the Cell drop-down menu:\n",
    "![play all button](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/play_all_button.png?raw=1)\n",
    "Half of the cells in this tutorial contain code, the other half contain visualizations and explanatory text. Code, visualizations, and text in cells can be modified - you are encouraged to modify the code as you advance through the tutorial. You can inspect the implementation of a function used in a cell by following these steps:\n",
    "![inspecting code](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/inspecting_code.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "wORsai47hfZi",
    "outputId": "fdc9597b-d9ff-4496-ca1a-aaac13a21583"
   },
   "outputs": [],
   "source": [
    "#uncomment the lines below if you are running this tutorial from Google Colab \n",
    "#!pip install dragonn>=0.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSaW2fD2hfZk"
   },
   "outputs": [],
   "source": [
    "# Making sure our results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-bvAg5-hfZn"
   },
   "source": [
    "We start by loading dragonn's tutorial utilities and reviewing properties of regulatory sequence that transcription factors bind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1e2J6BZ-hfZo"
   },
   "outputs": [],
   "source": [
    "#load dragonn tutorial utilities \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e3bYhMBhfZr"
   },
   "source": [
    "## Key properties of regulatory DNA sequences <a name='2'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "![sequence properties 1](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/sequence_properties_1.jpg?raw=1)\n",
    "![sequence properties 2](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/sequence_properties_2.jpg?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ga1AXeKXhfZs"
   },
   "source": [
    "## Learning to localize homotypic motif density <a name='3'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "In this tutorial we will learn how to localize a homotypic motif cluster. We will simulate a positive set of sequences with multiple instances of a motif in the center and a negative set of sequences with multiple motif instances positioned anywhere in the sequence:\n",
    "![homotypic motif density localization](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/homotypic_motif_density_localization.jpg?raw=1)\n",
    "We will then train a binary classification model to classify the simulated sequences. To solve this task, the model will need to learn the motif pattern and whether instances of that pattern are present in the central part of the sequence.\n",
    "\n",
    "![classification task](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/homotypic_motif_density_localization_task.jpg?raw=1)\n",
    "\n",
    "We start by getting the simulation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5-27zcHhfZt"
   },
   "source": [
    "## Getting simulation data <a name='4'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "\n",
    "DragoNN provides a set of simulation functions. We will use the **simulate_motif_density_localization** function to simulate homotypic motif density localization. First, we obtain documentation for the simulation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.simulations import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "kv-SkzqXhfZt",
    "outputId": "945efaff-fa1c-437b-a41d-d7e02c77852f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Simulates two classes of seqeuences:\n",
      "        - Positive class sequences with multiple motif instances\n",
      "          in center of the sequence.\n",
      "        - Negative class sequences with multiple motif instances\n",
      "          anywhere in the sequence.\n",
      "    The number of motif instances is uniformly sampled\n",
      "    between minimum and maximum motif counts.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    motif_name : str\n",
      "        encode motif name\n",
      "    seq_length : int\n",
      "        length of sequence\n",
      "    center_size : int\n",
      "        length of central part of the sequence where motifs can be positioned\n",
      "    min_motif_counts : int\n",
      "        minimum number of motif instances\n",
      "    max_motif_counts : int\n",
      "        maximum number of motif instances\n",
      "    num_pos : int\n",
      "        number of positive class sequences\n",
      "    num_neg : int\n",
      "        number of negative class sequences\n",
      "    GC_fraction : float\n",
      "        GC fraction in background sequence\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sequence_arr : 1darray\n",
      "        Contains sequence strings.\n",
      "    y : 1darray\n",
      "        Contains labels.\n",
      "    embedding_arr: 1darray\n",
      "        Array of embedding objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print_simulation_info(\"simulate_motif_density_localization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CzKV_rDhfZw"
   },
   "source": [
    "Next, we define parameters for a TAL1 motif density localization in 1500bp long sequence, with 0.4 GC fraction, and 2-4 instances of the motif in the central 150bp for the positive sequences. We simulate a total of 3000 positive and 3000 negative sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CgzxAhShfZw"
   },
   "outputs": [],
   "source": [
    "motif_density_localization_simulation_parameters = {\n",
    "    \"motif_name\": \"TAL1_known4\",\n",
    "    \"seq_length\": 1500,\n",
    "    \"center_size\": 150,\n",
    "    \"min_motif_counts\": 2,\n",
    "    \"max_motif_counts\": 4, \n",
    "    \"num_pos\": 3000,\n",
    "    \"num_neg\": 3000,\n",
    "    \"GC_fraction\": 0.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HpAcK0mhfZz"
   },
   "source": [
    "We get the simulation data by calling the **get_simulation_data** function with the simulation name and the simulation parameters as inputs. 1000 sequences are held out for a test set, 1000 sequences for a validation set, and the remaining 4000 sequences are in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8cJCmy9hfZ0"
   },
   "outputs": [],
   "source": [
    "simulation_data = get_simulation_data(\"simulate_motif_density_localization\",\n",
    "                                      motif_density_localization_simulation_parameters,\n",
    "                                      validation_set_size=1000, test_set_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulation_data provides training, validation, and test sets of input sequences X and sequence labels y. The inputs X are matrices with a one-hot-encoding of the sequences:\n",
    "<img src=\"https://github.com/kundajelab/dragonn/blob/master/paper_supplement/tutorial_images/one_hot_encoding.png?raw=1\" width=\"500\">\n",
    "\n",
    "Here are the first 10bp of a sequence in our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_data.X_train[0, :, :10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLupnMwqhfZ-"
   },
   "source": [
    "We can convert this one-hot-encoded matrix back into a DNA string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "05S6ivnThfZ-",
    "outputId": "f973f351-6369-462d-e0b5-4a6e07ad7579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAGTGCAAAA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dragonn.utils import *\n",
    "get_sequence_strings(simulation_data.X_train)[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrtwHPxthfaA"
   },
   "source": [
    "Let's examine the shape of training, validation, and test matrices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zzNTlHQmhfaB",
    "outputId": "0e599623-7dbc-4c79-b9b6-6a578297f828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1, 1500, 4)\n",
      "(4000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(simulation_data.X_train.shape)\n",
    "print(simulation_data.y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "J89jB_BFhfaE",
    "outputId": "493564bd-68f1-4feb-d632-cd9d0c727051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 1500, 4)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(simulation_data.X_valid.shape)\n",
    "print(simulation_data.y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "A6tHqiBEhfaH",
    "outputId": "06239636-4639-42f8-8a5f-a875d9617cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 1500, 4)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(simulation_data.X_test.shape)\n",
    "print(simulation_data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running dragonn on your own data: starting with FASTA files <a name='4.5'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Dragonn on your own data, you can provide data in FASTA sequence format. We recommend generating 6 fasta files for model training: \n",
    "* Training positives \n",
    "* Training negatives \n",
    "* Validation positives \n",
    "* Validation negatives \n",
    "* Test positives \n",
    "* Test negatives \n",
    "\n",
    "To indicate how this could be done, we export the one-hot-encoded matrices from **simulation_data** to a FASTA file, and then show how this fasta file could be loaded back to a one-hot-encoded matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.utils import fasta_from_onehot\n",
    "\n",
    "#get the indices of positive and negative sequences in the training, validation, and test sets \n",
    "train_pos=np.nonzero(simulation_data.y_train==True)\n",
    "train_neg=np.nonzero(simulation_data.y_train==False)\n",
    "valid_pos=np.nonzero(simulation_data.y_valid==True)\n",
    "valid_neg=np.nonzero(simulation_data.y_valid==False)\n",
    "test_pos=np.nonzero(simulation_data.y_test==True)\n",
    "test_neg=np.nonzero(simulation_data.y_test==False)\n",
    "\n",
    "#Generate fasta files\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_train[train_pos],axis=1),\"X.train.pos.fasta\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_valid[valid_pos],axis=1),\"X.valid.pos.fasta\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_test[test_pos],axis=1),\"X.test.pos.fasta\")\n",
    "\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_train[train_neg],axis=1),\"X.train.neg.fasta\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_valid[valid_neg],axis=1),\"X.valid.neg.fasta\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_test[test_neg],axis=1),\"X.test.neg.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine \"X.train.pos.fasta\" to verify that it's in the standard FASTA format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0\r\n",
      "AAGTGCAAAAAACAGACAAGATGGGTACAACGTTATCCAACGTGAGTAAATAGCTGATGAAACAGGCAGCTTTTCTCTGAATCAGAAATATACAGGTTTCCGCACCTATTTGTATAGAAGCGAACGTTCTGAGGTATGAATACGATGATAATGACTAACAGAAGTGTTTGCAGAGCGGGTGATTCCGCGTATTTCGCCAACAAGATAACATCAAGCAAATCAAGTTTACCGCTGCTGAGTGATATATAAAGGGATTCACTTAATCGTTTGTATAATTTGAGAGCAGTTATTCTACTACAACTGATTCATTACCTAAACTATGTTTATATCATCCCCAGCAAATTTATTCTTTGTAAAGTAATTAAAAAATACTTCACCCACTAATCTATATATTTTATGAAATCCATGATGTTCCTAATGTGTCAGACCCGGATCTCACACGGATGAGAGAGTTGGACACTGTTGATGCATTGATACAGGGAAAGTGTAAGACTATCGAAGAGCCTTCCAATGTCAGATTTAATCGTACAATTGAATTGTCTTATAACTCATGAGCCTTTTCCAAGAGAGTCTCATCGGCCATACTTTGATATCGTGTTGTAATTCACAAAGCTAGAAATAGGGGGATGTAAGCTCCCGATATTCTTATCCTAATAGGCTTAGTCAGACCAGTCGAACAGTCCAGCTGCCTACGCGTACTCATAGAGTCCTGGCCACCTGCTACATGCGTGGGCAAGCTATCACGGCAAGGTCCTGTATCGCCACCTGCTCGGCTTCCCTGAAGATGAAGATGCTGGTCAATGAAAAGTGCTATGATAGCATACGAACCTGTATTTAATCGATCTAACCATGTGTGAGTTCATTAACTCTTGGGCATATGTTTTCTTGATTCCTGCTTGTGCTTTCTGTTCTTTGAAAACGTATGTTCTTCTTATCTATGACTCCTTAGCAAAACATAATGATACACCTCTTAATACGCTAAAATAGATATGTAGTGCTTTCCATAAGTTGTCGTATCACTTGTCCCCCTTAACGGCGGATCAAGCTTATGGTACCAGTCAATCAAGCACATCCGCTACAATCTCAAAGCACCTTTTACTATATAATATAAAACCCATTGAACAAATGATGTGCCCATCAACTCCTAATCCAGTTAGTTAATCCTAAGGTAGAGGCCCTTCTCCGGCCTCGATATAGACACGAGCTCAATCCCAAGAAAATAATCTTCCACACTGTTTAGTTTCAGGTCTTTTTACCCGCCAACCAAAACACTAGTTTAAGGTGTACAAATCTTTCTCTGTTCCATGAGTTTCAAAAGATGTAGTAAAAAAACCCGTGTTTGACCGTGTAGAAACACAAATCTTCGACTTAACCGTAAACCATCAATGTAACCAAAAAACGTGCCAGCGCACAATAGTCCAATCCATACTTTAAACCAACCATACCCGGGTATGTACTCGTGGGTATTCAACTCAATATTGGTTTTTACTGCTAAACTTT\r\n",
      ">1\r\n",
      "CTCGTGGAGCACAATTGTTCCTCGTTATTTCCTCAATAAAGCTAGTTATGTATGGTGTTTAACGTCGAATGACAACTTTGGTCAGAATATGTAAGGTGGCAACTCGTATCCAACTTACTAATTTGATAAACAAACAGCGGAGTCATTCTACTGGTGTATGTATTCATTAACCTCAACAGCATTATTTATATTAGGAAGTTCTTAGAGGAGGGATTCGGTCTACGTCCTCGATGCGGCTCTAACAGTGTGAAATACAAGCTAATTTGAATTTACCGCCGAACCTGTGATCTCGAAGAAGAGTTATCATATCACTAAGGTCGTTAAGCAATCGTGAAGAATGTCTAAAGAGCCCACTGGAAACAAAATTCTGTAGTCATCTATCCTTTAACCTTTTAGTATCTAAAAGCTGAAATCTAATTCAAGATATTACTGTGATGATCATGTCTGTTAAGATACAAGACTCCCAAGCATTAACCAAGAGAAGCTACCTACCTGACCTTCATACGTAGTTGTAGTTCTATTAGGTCAAAAGATCGGACTTATGTTTCTCTCACTAGTCGAGCAACATTGCCAGTAGAGCGCTTTTATTTTAATATATATCCTACGTACGGATCTACACTCATACCCAATCCGATTAAATCGCTGCGATGCAGCAATTCGGTGAGGTAAACGTTGCCAGGATTACTAGCCAGCTGGTATTGTTCCCACATTCTCGACTTCTATTCGATGCTCACTTATATATTACCACCTGACTATTATCAAAATAGGTACTCACAGTATCTCTTCGATGGAGAAAACCACCTTATCGAAACTGACAACACTTCGTTACTACAGAAAGAACCCGTATTTTCGAAAATTCTTATTAGATTACTCGAAGAATGGACAAGATGGCCAACTTGACTAGGGATTCAAACCTCGCGGGGAGTGGAAAACATTGTAGTTATAAATTATCGACCTATGGCATTATAGAAAACCTAAATAAATCAAAATAATATATGGCTTCTAGCACTACATCCAACCTGACCAGCGACCTCGCTTTGGCGTCACCCTCAATATATCTAAGAGGCTACAAACTCCTCGCTATCGCCAGTAGAAAACTTCAGAAGCCTCATCTCTAAACATAGTAAACGACCTATTTTAAAAACTTCGCACATATATTATGGGTGCATACGCTTGGATTGGAGCCTCCAAGTTTATTTCTGACGATAATGATACCAGGAACAGCACAGTCTTAAATAGTAATCACTAACACCTCTCTAGAAGAGTTACCAATTCTTTTATATGGGTAAAGAGTTCAATAAAAATTTTATAGGGACGCGCGGTTGTTCAGTTGACCTAGTTCTCCGAATCGTATCAATATTAGCGATCTGTAGGTTACACGTCAAACAGATGTTTAAGTACATCATTAATTTCCTGAGCGCCTGTGTACAAGGAAGGCTCATGTTTATAGCCTGATTGTCCGCACTGGCCAGTGTCATAGTATAGTAAAGTCTAGTAAAC\r\n",
      ">2\r\n",
      "TTCGTTGTTAACGCCAGTCATAGTATCATTTAACAATCGCCGATTATACATAATCATGTATGGTAAGACGATAGCAGCGACCCATATGGGGAGAGGCTCGGGGGCGCGCAACCTCTCACCGAATTCATGAAAATATGCATAGTTGATCGCTGAGGGAAGTCGGAATGTAATCACGAGACCGCCCACCTCCTTTACCGGTATCTACCTGACCATTTTAAATTGCATGGAAGTTGGAGCTTGAGGACTGGAATGGTCATATCCAATGAACGGTATCTTTGCGTGTTATAATTCAAATTATTGGATCGTAGTAACGATACGACATTGGCGATTCGGTTTTAGATGTTCTTTAACCCTATGTTTAATCGGGCGTTGGCGTGAAAATATCTCTGTTGCGCGGAATGCTACGTAATCTTGTACCAAAGATAAGTACATAATAGCGTATATGAACATTATGATGGGAACATTTGATTGCGGTTTTGAGCGGGCCCATTCCTGGCGACGTTGATCGAGTAAAATCTTGACCTGTGACATCTTGAGTTAAGGACTATATTATGGCTACCGCAAATAGATCCCGACCCTCGAAGAATGACATGCGAAGGCCGATTTACAAGATATACTTTGCTTTCCTATTTAAGTACCAGCCTTTACTCATGATGAGCATGTTACCTAGCTTGCCTCATTTTTCTGCTGACCGACTATGATGCTATTAGTGCCACTTCAATAAAATTTACCTCTTCTATCGTCGGGAGTAAAACCAGATGGTTCAAGATATGTACATGTATATTCCATCTGTTGCACCATCAGCAATCACTAGTTGCTTATATATTTTTAACCGCTTTACTCAAGTATATTCTAGATAATTCAGTCGATGTCTGATAGGCCCCTACTAGGCTGTACTAGATCTACTGGCATATTGCCATGTTGTACCTAATATAGGATTATTGCTAGTCCACAAACAACACATTCCTAAAGGCCTCTTTATAAATAGCATGGCATTTGACTCTGACATGCGAGAAAGTTTGTTGAGTGAATCCACTTATATGAAATGCTTCAGTAGGCATCTGTGCAACTTGTTATAATGCCCTTTTCTGTTCTTTCTTCTAAGATAGAAGCTACAACGCGCTTAAAGTTCACACTGCGTTGTTGTCAAATTTACGGAGTTCCCGTAGAAGAAAAAGAGTATGTGTCAATTTTGCGTCTTAGGGTTTTATAAGGAAAATTTAGTTAACTTGACGGACGACAAAGCCATGCCATTTTCGCATTGAAGATGGCTAGTGGAAAACTTTCTTTTTCCTACCATAACATAGTCATATTTATCTATGTGAATATTCCACTCCTCTGTTTACTTTAATGATAGTTAAAATCCTAGAGATCATGATAGCTCGTTATTGGCACTATAGGTGTCTAGTGTTATCAATCGTGCAAACTAAAAGTTAATCTAAGGCCAATGTGGCCTAATCCTGTGTACACGAGCGAGCACGAGAGGGAGATTGAGCCCTG\r\n",
      ">3\r\n",
      "CACCTTTGATAAACGACTTAAGCTAATCTTGATCGGGAACTGATGATGAGAGTTTATGTTAATAATTAGGATATGATGCATATTTTCAATAAGTTTAGCTCTCCTGTTCTCACTGCCGCAGGGGACAACGTTAGTAGTAGAAACCTATCTCTCCACATACGGGTAGTAAAGACAGATACAGTTCTAGTCGATCACCGTGATGGTACAATTCTAACGGTTTCTAGCACTCTACATATCCGTCGATAACCCAATTTCTGCTACACTCTTTCATAACCCGGAACCGTAGGGTCGACCCAATTAAACTATTTGTAAAATCGCTTCTTGAATACAAGGAGTCCTTGTTTATTATAAGCCTAACTTCATGTGCTGCATGTGTGACTAGTACATGCTCTTAGTTTACAAAACCCCTGTTCATTTATACTTCTGGTCCTAGTTTATCCGAATTAACAACACCAAATCTTCTTGAGCTGTACTATAGACTACTAGCCTTTAGCCTACAAATTCGATCGCTAAGAAGGCTCTTCTAAAGAAGCGTTTATAGGCCTTCAAAATTATACAATGTGCATAGCGCGGAAGAACGGAAGTTCCGTTTCACCAATAGCAGCTTATATTTTGTTACTACCCTTCAGCAGCGTTCAAATCTTGATGTTTCCCAGAAGATAGCGTTTCGCATGGATGGCAGGTGGTCTTTTCAAAGCTTTAATTCATTGAGTTGACAATATATCGCTAATGAAGATGCCAGCTGCTTTTTTGAACAACTTTTTGCAAGATTCCTGCACACCACCACCTGTTTACAATTCATTTTACAGCTGAAATCTTAATACGAGTATGTCTCTCATCCTCTTGGAGTCAATAATGGTTAATAATTCTGATAGAATTCGACTAGCTTTCAGAATTGCTAAATTAAAAAGATTGTACAAGTGAATAAGCGGCAATATACCTTAAGGATCTAAATAGGTCATGTAAACCAATGTGAGCTTTTAATAACAGCGGTATGAACATATCTATATTAAAGGATGACTGGTATTCTATCGTTTCACGAGTGCATAAACGATTTTGCCGTCAATTGAGAGCATCTTGACATACATTACGATTATTCATACAAAGGTATGTGGTGCACTTAGGGTTTGTTGCGTATTGGTTAAAAAGAAGATCATGAGGCCAACCCATTCCACATCAGCATTAACATGAAATGACGCTTACATTCAACTTCTTATGACTATGTACTGGGAAACAGTAAACTTTTTCTATCGCATTGTGTTAAATACTAATTGTCAAAATGCTTTAATTAAGAATGTTTTAGGAATGTCTATCTGAGCCTGCCTGTGGTAGGGCCAAGCGATGGTCCCCTTAAGTGGAGTTTTTAAAATCTTGTGTCCAGTATGACCTGCGTAACTGGACAAGCCTGGTCCGGGATTTGAAAAATTATGTTTTCGTCACCCTCCGCGTCGACTAAGCCGAAAGCTGATTGTTCTTAGCCTTTGGGCGATATCAATCATA\r\n",
      ">4\r\n",
      "GTTGATAATGAGAAGCGTACATTCCAGCGCAAGTGGCCTAAATTAGGAATGTACTCGGTACTTAATGGAGGTTGTAACAGTGTTATTACTAAATGCCCAAACATAAACATATGTATGTCAGTTTTATCATTCGACGAATCTATAAAAAATATCCGATCACTTGCATTCAAATCATCATGTGTTCATTGACCAACTGTGAATTTTCCAAGAGCTACCATACCGTGTGCCTTCTATCTCGGTGAGCCGTACCGGAGCGCTAATTTTTGTTTACTCAATTCTATTCAAACACCTGTCCCATCCAAAATTCTATTCAGCACATTCATGCGGATAGCTAAATCAAACGCTGTAATTCGGAGAGAAGCCGAGGACAAGTGCTGATGAAACAACATATACCTGCCAAACAGTGAAGTAACGAAGGAATTCTATTCTACGTTACATTACAATGAGCAGGCAACGAAGTATTATCAATACAGCCCATGATCAGGGGCTTCGCACTCAACCGTATATCAGTATATGCCATTTCCTTAAAACCGGCTGGACGCACAGATGGTGCGTTCCTACTTAGATTGTATATGGGAAAGATTCATGGTTTCGACGAATCGCATGGTTACATGGACTTACTGGACCAGACGATTGCATCACATGAGCGCAAGTTACGATGATCGACCTTGCATTATCCGCATAGAGTAAGTCCTGCAGTGTCCATCTGCTCGGTTAACTAACCCTAGAGTTAGCCATCTGACATAAAGTATTTCCACCTGGCAATCCAGTGATTTACCAGCTGGTCTTACCTTGCGAAAGCTTGTTGATGTTACATGAAGTGCCTAAATAAGCCGTGGATGCTATTTATAGCATATGTATAGTGATAATGATTCCAGAGCTGTGTGAGCTCGTTTATATTCAACAGATGACATAAGGAGCTCTTACTCCCGTTATTCTGCGCATATCTGTGATTACTTATGTAGTTATGATTGGCTTGAAAGAGTTATAAAGTCACGGTGACAGATTACTACATTGGTTGCTGAACTACGATCGAGAGAATTAAAACCGGATCCGGCTTATATAGCGCCATTGTTAACCGATTAGGATATATTGAACCAGAGGCAAAAATTCTGTCACTATGAGCTTATGTGGGTATTTAATCGATTATGAATCTAATTACACACCTGCGTTGCCTAAAGTCATCACTGATGGATACAAGAACCGTATAGGATAGGATCCTAAAATTGCTCCGCCTTAAGTATTCCCAGGAACATACTAGGGTTTCGTTTACAGCACTTGAACCAATCTTGGGAACTAAGAGAACTCTAACCAAACCAGACCTTCCAATTCTTGTTTCTTTATGAACCAACGAGGTGACGCTGCAGTGACCAATTTAGGACATACCGCCGGGTTAAGCATCTATTACACGATAGCCAGAAGTGCTAAGTTGACCTCTAGTCACAACTCTTGGTTCATTTGCTTTCCCCTCGCCTAATATTAAGGATCAACTAAGGACTT\r\n"
     ]
    }
   ],
   "source": [
    "! head X.train.pos.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load fasta format data to generate training, validation, and test splits for our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.utils import encode_fasta_sequences\n",
    "X_train_pos=encode_fasta_sequences(\"X.train.pos.fasta\")\n",
    "X_train_neg=encode_fasta_sequences(\"X.train.neg.fasta\")\n",
    "X_valid_pos=encode_fasta_sequences(\"X.valid.pos.fasta\")\n",
    "X_valid_neg=encode_fasta_sequences(\"X.valid.neg.fasta\")\n",
    "X_test_pos=encode_fasta_sequences(\"X.test.pos.fasta\")\n",
    "X_test_neg=encode_fasta_sequences(\"X.test.neg.fasta\")\n",
    "\n",
    "X_train=np.concatenate((X_train_pos,X_train_neg),axis=0)\n",
    "X_valid=np.concatenate((X_valid_pos,X_valid_neg),axis=0)\n",
    "X_test=np.concatenate((X_test_pos,X_test_neg),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.concatenate((np.ones(X_train_pos.shape[0]),\n",
    "                        np.zeros(X_train_neg.shape[0])))\n",
    "y_valid=np.concatenate((np.ones(X_valid_pos.shape[0]),\n",
    "                        np.zeros(X_valid_neg.shape[0])))\n",
    "y_test=np.concatenate((np.ones(X_test_pos.shape[0]),\n",
    "                        np.zeros(X_test_neg.shape[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having read in the FASTA files, converted them to one-hot-encoded matrices, and defined label vectors, we are ready to train our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giRBRUbEhfaK"
   },
   "source": [
    "# Defining the convolutional neural network model architecture  <a name='5'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "A locally connected linear unit in a CNN model can represent a PSSM (part a). A sequence PSSM score is obtained by multiplying the PSSM across the sequence, thresholding the PSSM scores, and taking the max (part b). A PSSM score can also be computed by a CNN model with tiled, locally connected linear units, amounting to a convolutional layer with a single convolutional filter representing the PSSM, followed by ReLU thresholding and maxpooling (part c).\n",
    "![dragonn vs pssm](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/tutorial_images/dragonn_and_pssm.jpg?raw=1)\n",
    "By utilizing multiple convolutional layers with multiple convolutional filters, CNN's can represent a wide range of sequence features in a compositional fashion:\n",
    "![dragonn model figure](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/tutorial_images/dragonn_model_figure.jpg?raw=1)\n",
    "\n",
    "We will use the deep learning library [keras](http://keras.io/) with the [TensorFlow](https://github.com/tensorflow/tensorflow) backend to generate and train the CNN models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMEgqp-bhfaL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#To prepare for model training, we import the necessary functions and submodules from keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dropout, Reshape, Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta, SGD, RMSprop;\n",
    "import keras.losses;\n",
    "from keras.constraints import maxnorm;\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.callbacks import EarlyStopping, History\n",
    "from keras import backend as K \n",
    "K.set_image_data_format('channels_last')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80GBS3CFhfaN"
   },
   "source": [
    "# Single layer, single filter model <a name='6'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfS72LrxhfaN"
   },
   "source": [
    "We define a simple DragoNN model with one convolutional layer with one convolutional filter, followed by maxpooling of width 35. \n",
    "\n",
    "The model parameters are: \n",
    "\n",
    "* Input sequence length 1500 \n",
    "* 1 filter: this is a neuron that acts as a local pattern detector on the input profile. \n",
    "* Convolutional filter width =  10: this metric defines the dimension of the filter weights; the model scans the entire input profile for a particular pattern encoded by the weights of the filter. \n",
    "* Max pool of width 35: computes the maximum value per-channel in sliding windows of size 35. We add the pooling layer becase DNA sequences are typically sparse in terms of the number of positions in the sequence that harbor TF motifs. The pooling layer allows us to reduce the size of the output profile of convolutional layers by employing summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "1ikMRDXRhfaO",
    "outputId": "058e4a1e-a694-4372-9ceb-fe73b002fecc"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 12644188160",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ac7df3e0ac4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mone_filter_keras_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mone_filter_keras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimulation_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mone_filter_keras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mone_filter_keras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mone_filter_keras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    183\u001b[0m         normed_training, mean, variance = K.normalize_batch_in_training(\n\u001b[1;32m    184\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             epsilon=self.epsilon)\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mnormalize_batch_in_training\u001b[0;34m(x, gamma, beta, reduction_axes, epsilon)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \"\"\"\n\u001b[1;32m   1857\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_has_nchw_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m             return _broadcast_normalize_batch_in_training(x, gamma, beta,\n\u001b[1;32m   1860\u001b[0m                                                           \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_has_nchw_support\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m    291\u001b[0m     \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_current_explicit_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mgpus_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpus_available\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    185\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 12644188160"
     ]
    }
   ],
   "source": [
    "#Define the model architecture in keras\n",
    "one_filter_keras_model=Sequential() \n",
    "one_filter_keras_model.add(Conv2D(filters=1,kernel_size=(1,10),padding=\"same\",input_shape=simulation_data.X_train.shape[1::]))\n",
    "one_filter_keras_model.add(BatchNormalization(axis=-1))\n",
    "one_filter_keras_model.add(Activation('relu'))\n",
    "one_filter_keras_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "one_filter_keras_model.add(Flatten())\n",
    "one_filter_keras_model.add(Dense(1))\n",
    "one_filter_keras_model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "_JhL10vzhfaQ",
    "outputId": "1b6782fc-3479-4ff5-8c9d-db807f56ec9d"
   },
   "outputs": [],
   "source": [
    "one_filter_keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rzKZVoNhfaS"
   },
   "outputs": [],
   "source": [
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "one_filter_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xwSZhvVhfaV"
   },
   "source": [
    "We train the model for 150 epochs, with an early stopping criterion -- if the loss on the validation set does not improve for five consecutive epochs, the training is halted. In each epoch, the one_filter_dragonn performed a complete pass over the training data, and updated its parameters to minimize the loss, which quantifies the error in the model predictions. After each epoch, the performance metrics for the one_filter_dragonn on the validation data were stored. \n",
    "\n",
    "The performance metrics include balanced accuracy, area under the receiver-operating curve ([auROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)), are under the precision-recall curve ([auPRC](https://en.wikipedia.org/wiki/Precision_and_recall)), and recall for multiple false discovery rates  (Recall at [FDR](https://en.wikipedia.org/wiki/False_discovery_rate))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjRCE1JJhfaV"
   },
   "outputs": [],
   "source": [
    "from dragonn.callbacks import * \n",
    "#We define a custom callback to print training and validation metrics while training. \n",
    "metrics_callback=MetricsCallback(train_data=(simulation_data.X_train,simulation_data.y_train),\n",
    "                                 validation_data=(simulation_data.X_valid,simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "eJT2c7XFhfaX",
    "outputId": "51b2bd94-5e15-489a-f954-093c8670e99e"
   },
   "outputs": [],
   "source": [
    "## use the keras fit function to train the model for 150 epochs with early stopping after 3 epochs \n",
    "history_one_filter=one_filter_keras_model.fit(x=simulation_data.X_train,\n",
    "                                  y=simulation_data.y_train,\n",
    "                                  batch_size=128,\n",
    "                                  epochs=150,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                            History(),\n",
    "                                            metrics_callback],\n",
    "                                  validation_data=(simulation_data.X_valid,\n",
    "                                                   simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSmch4Hghfaa"
   },
   "source": [
    "### Evaluate the model on the held-out test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCCsY5aohfab",
    "outputId": "4d6c7011-70f3-416c-8b77-66de5a996bb5"
   },
   "outputs": [],
   "source": [
    "## Use the keras predict function to get model predictions on held-out test set. \n",
    "test_predictions=one_filter_keras_model.predict(simulation_data.X_test)\n",
    "## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "print(ClassificationResult(simulation_data.y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSYLNtjjhfaf"
   },
   "source": [
    "### Visualize the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtqlbmnmhfag"
   },
   "source": [
    "We can see that the validation loss is not decreasing and the auROC metric is not decreasing, which indicates this model is not learning. A simple plot of the learning curve, showing the loss function on the training and validation data over the course of training, demonstrates this visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WSa4OyEhfah",
    "outputId": "ea46fbca-1538-4611-9b76-3c9cc73534ce"
   },
   "outputs": [],
   "source": [
    "from dragonn.vis import plot_learning_curve\n",
    "plot_learning_curve(history_one_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaBJrS2Qhfal"
   },
   "source": [
    "## Visualize the learned parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWMTRBqJhfal"
   },
   "source": [
    "Next, let's visualize the filter learned in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u71ItwHBhfan"
   },
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vwx8sbtuhfan"
   },
   "outputs": [],
   "source": [
    "from dragonn.vis import plot_model_weights \n",
    "plot_model_weights(one_filter_keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9Ja44dfhfau"
   },
   "source": [
    "### Convolutional layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8v541M5mhfav"
   },
   "outputs": [],
   "source": [
    "W_conv, b_conv = one_filter_keras_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuBSKMy-hfax",
    "outputId": "494331c0-6df0-4a67-fb23-18bd7a0795c9"
   },
   "outputs": [],
   "source": [
    "W_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWVP0eEPhfay",
    "outputId": "27c7dd17-4c46-4a8c-d248-295b7c13c050"
   },
   "outputs": [],
   "source": [
    "b_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRjf1T--hfa0",
    "outputId": "cce723b4-8b82-4b71-831a-9b63b3dd9d1d"
   },
   "outputs": [],
   "source": [
    "from dragonn.vis.plot_kmers import * \n",
    "plot_filters(one_filter_keras_model, simulation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maUwPZMzhfa2"
   },
   "source": [
    "# A multi-filter DragoNN model <a name='7'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "Next, we modify the model to have 15 convolutional filters instead of just one filter. Will the model learn now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haYtjeSBhfa2"
   },
   "outputs": [],
   "source": [
    "#Define the model architecture in keras\n",
    "multi_filter_keras_model=Sequential() \n",
    "multi_filter_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "multi_filter_keras_model.add(BatchNormalization(axis=-1))\n",
    "multi_filter_keras_model.add(Activation('relu'))\n",
    "multi_filter_keras_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "multi_filter_keras_model.add(Flatten())\n",
    "multi_filter_keras_model.add(Dense(1))\n",
    "multi_filter_keras_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "multi_filter_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYqqBqUfhfa5",
    "outputId": "75c4e551-62c2-4441-abe1-21ba80b8c596"
   },
   "outputs": [],
   "source": [
    "multi_filter_keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zvq60DgZhfa6",
    "outputId": "d171cbdc-c3b9-451f-e84a-830c3bb18685"
   },
   "outputs": [],
   "source": [
    "## use the keras fit function to train the model for 150 epochs with early stopping after 3 epochs \n",
    "history_multi_filter=multi_filter_keras_model.fit(x=simulation_data.X_train,\n",
    "                                  y=simulation_data.y_train,\n",
    "                                  batch_size=128,\n",
    "                                  epochs=150,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                            History(),\n",
    "                                            metrics_callback],\n",
    "                                  validation_data=(simulation_data.X_valid,\n",
    "                                                   simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Xo0m9IUhfa8",
    "outputId": "ca487c4b-78c8-49d6-99db-2f9e3fa8e503"
   },
   "outputs": [],
   "source": [
    "## Use the keras predict function to get model predictions on held-out test set. \n",
    "test_predictions=multi_filter_keras_model.predict(simulation_data.X_test)\n",
    "## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "print(ClassificationResult(simulation_data.y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1zTLiJ4hfa_",
    "outputId": "75fe7307-9d3e-4e54-c29b-811318d37653"
   },
   "outputs": [],
   "source": [
    "## Visualize the model's performance \n",
    "plot_learning_curve(history_multi_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rVk6hp5hfbA",
    "outputId": "d1019b43-5ed4-4668-b533-25e5702dff80"
   },
   "outputs": [],
   "source": [
    "## Visualize the motifs learned by the model\n",
    "plot_filters(multi_filter_keras_model, simulation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHsr3OughfbB"
   },
   "source": [
    "# Model Interpretation <a name='8'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8n_EMffXhfbC"
   },
   "source": [
    "As you can see, the filters/model parameters are difficult to be interepreted directly. However, there are alternative approaches of interepreting sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzPdGqgDhfbD"
   },
   "source": [
    "Let's examine a positive and negative example from our simulation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Spz3zpGhfbE",
    "outputId": "843855d0-51d6-4098-8340-ae08c1fc2886"
   },
   "outputs": [],
   "source": [
    "#get the indices of the first positive and negative examples in the validation data split\n",
    "pos_indx=np.flatnonzero(simulation_data.y_valid==1)[0]\n",
    "print(pos_indx)\n",
    "pos_X=simulation_data.X_valid[pos_indx:pos_indx+1]\n",
    "\n",
    "neg_indx=np.flatnonzero(simulation_data.y_valid==0)[1]\n",
    "print(neg_indx)\n",
    "neg_X=simulation_data.X_valid[neg_indx:neg_indx+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnZ939dqhfbJ"
   },
   "source": [
    "### Motif Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ESoHCt9hfbJ"
   },
   "outputs": [],
   "source": [
    "pos_motif_scores=get_motif_scores(pos_X,simulation_data.motif_names,return_positions=True).squeeze()\n",
    "neg_motif_scores=get_motif_scores(neg_X,simulation_data.motif_names,return_positions=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAsR6VhphfbL",
    "outputId": "3a295714-45b1-4264-e6eb-ecc647bbf789"
   },
   "outputs": [],
   "source": [
    "plot_motif_scores(pos_motif_scores,title=\"Positive example\")\n",
    "plot_motif_scores(neg_motif_scores,title=\"Negative example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMnKaNighfbN",
    "outputId": "28108c18-7dc8-4342-da49-bc7df9145ff3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Negative example')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAADgCAYAAACgqLcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xu8XGV97/HPlwQoBhTQoBCuWgwiVdAUsVSLN27lCG1phSpFxaa0eGuVCnoqrdpTPZzqscVbqgi1ingBylE05KBopYpAuIsIIh6SIBchgJICCb/zx6ytw3ZmZ5LZs2fvPZ/36zWvWetZz1rrN/DslT2//VxSVUiSJEmSJEn92GTYAUiSJEmSJGnmM8kkSZIkSZKkvplkkiRJkiRJUt9MMkmSJEmSJKlvJpkkSZIkSZLUN5NMkiRJkiRJ6ptJJkmSpA2Q5CtJjh12HMOQ5Iwk7xl2HJIkaXoyySRJkqa1JLcmuSPJvLay1yW5eAru/bdJ/q29rKoOqaozB31vSZKkmcYkkyRJmgnmAm8adhCSJEnqziSTJEmaCU4F3ppk604Hk+yRZFmSe5LcmOSP2o49Mcn/SXJ/ksuSvCfJt9qOfzDJbc3xK5K8oCk/GHg78IokP0tydVN+cdOTavMkq5Ps1Xat+UnWJNmu2T8syVVNvf9M8qxuH7DbZ0iyWXONNzT7c5JckuSdzf6+Sb7d3OP2JKcl2aztupXkL5LclOSBJO9O8rTmnPuTfG6sfpIDkqxI8vYkdze9yF45Qcw9fz5JkjT7mWSSJEkzweXAxcBbxx9ohtEtAz4DbAccDXw4yTObKh8Cfg48BTi2ebW7DNgb2La5xueT/FpVfRX4H8DZVbVlVT27/aSqegg4p7nfmD8CvlFVdyZ5DnA68GfAE4GPAecn2XxDPkNVPQy8CnhXkmcAJwFzgL9vTl8H/CXwJOD5wEuAvxh3i4OB5wL7AX8NLAFeCewE7DXuMzyludaC5r/VkiQLO8Tc8+eTJEmjwSSTJEmaKd4JvCHJ/HHlhwG3VtUnq2ptVS0HvggcmWQO8AfAKVX1YFV9D3jMfEpV9W9V9dPm3H8ENgd+JanSxWd4bILmj5sygD8FPlZVl1bVumYep4doJXrG6/oZmhivA94DnEsr0XZMVa1rjl1RVd9pzruVVrLnd8Zd/31VdX9VXQ9cB1xYVbdU1X3AV4B9xtX/m6p6qKq+AXyZVvJsvA35fJIkaQSYZJIkSTNCk2j5Eq2ePO12AZ7XDNlanWQ1rV46TwHm05rP6ba2+u3bJHlLkhuS3Nec+wRaPXl68TVgiyTPS7ILrR5R57bF9ZZxce0E7NDhOhN9hjFnArsCF1TVTW3xPz3Jl5L8JMn9tHpfjY//jrbtNR32t2zbv7eqft62/+MJYu7180mSpBEwd9gBSJIkbYBTgOXAP7aV3UZriNrLxlduejKtBXYEftAU79R2/AXA22gNMbu+qh5Nci+QpkpNFExT/3O0ejPdAXypqh5oi+vvq+rvu16gh8/Q5sO0kmwHJfntqhqbV+ojwJXA0VX1QJI30/SA2kjbJJnXlmjamVbvp04x9/r5JEnSCLAnkyRJmjGq6mbgbOCNbcVfAp6e5Jgkmzav30zyjGZI2TnA3yZ5XJI9gD9pO3crWkmou4C5zWTaj287fgewa5KJfmf6DPAKWj2PPtNW/i/A8U0vpySZl+R3k2zV4RpdPwNAkmNozan06uazn5lkrPfRVsD9wM+az/fnE8Taq79rJhx/Aa2hfJ/vUGdDPp8kSRoBJpkkSdJM8y5g3thO03PoQOAoYBXwE+B9tOZWAng9rSFwPwE+BZxFa+4ggKW05iT6Aa1hYf/FY4fTjSVXfppkeadgqupSWhOL79Bca6z8clrzFp0G3AvcTCtJ1OkaXT9Dkp2B/w38SVX9rKo+Q2si9A80p7+V1lxQD9BK/Jzd6R4b4CdNvKuATwPHV9X3O8Tc8+eTJEmjIVUT9gKXJEmaVZK8D3hKVY1fZW7kJTkA+Leq2nHYsUiSpJnHnkySJGlWS7JHkmc1Q7r2BY7jl5NzS5IkaZIMLMmUZKckX29Wa7k+yZua8m2TLEtyU/O+TZfzj23q3JTEvzRKkqSNtRWteZl+DnyO1qTh/z7UiCRJkmahgQ2XS7I9sH1VLW8mgLwCOILWWP17quq9SU4Ctqmqt407d1tacw0sorWqyxXAc6vq3oEEK0mSJEmSpL4MrCdTVd1eVcub7QeAG4AFwOHAmU21M2klnsY7CFhWVfc0iaVlwMGDilWSJEmSJEn9mZI5mZLsCuwDXAo8uapuh1YiCtiuwykLeOzKLiuaMkmSJEmSJE1Dcwd9gyRbAl8E3lxV9yfp6bQOZR3H9SVZDCwGmDdv3nP32GOPjQ1VkiRJkiRJ41xxxRV3V9X89dUbaJIpyaa0EkyfrqpzmuI7kmxfVbc38zbd2eHUFcABbfs7Ahd3ukdVLQGWACxatKguv/zySYpekiRJkiRJSX7cS71Bri4X4BPADVX1/rZD5wNjq8UdS+fVXZYCBybZpll97sCmTJIkSZIkSdPQIOdk2h84Bnhxkqua16HAe4GXJbkJeFmzT5JFST4OUFX3AO8GLmte72rKJEmSJEmSNA2lquNURzOSw+UkSZIkSZImV5IrqmrR+upNyepykiRJkiRJmt1MMkmSJEmSJKlvJpkkSZIkSZLUN5NMkiRJkiRJ6ptJJkmSJEmSJPXNJJMkSZIkSZL6ZpJJkiRJkiRJfTPJJEmSJEmSpL6ZZJIkSZIkSVLfTDJJkiRJkiSpbyaZJEmSJEmS1DeTTJIkSZIkSerb3EFdOMnpwGHAnVW1V1N2NrCwqbI1sLqq9u5w7q3AA8A6YG1VLRpUnJIkSZIkSerfwJJMwBnAacC/jhVU1SvGtpP8I3DfBOe/qKruHlh0kiRJkiRJmjQDSzJV1TeT7NrpWJIAfwS8eFD3lyRJkiRJ0tQZ1pxMLwDuqKqbuhwv4MIkVyRZPNGFkixOcnmSy++6665JD1SSJEmSJEnrN6wk09HAWRMc37+qngMcApyQ5IXdKlbVkqpaVFWL5s+fP9lxSpIkSZIkqQdTnmRKMhf4feDsbnWqalXzfidwLrDv1EQnSZIkSZKkjTGMnkwvBb5fVSs6HUwyL8lWY9vAgcB1UxifJEmSJEmSNtDAkkxJzgK+DSxMsiLJcc2hoxg3VC7JDkkuaHafDHwrydXAd4EvV9VXBxWnJEmSJEmS+jfI1eWO7lL+6g5lq4BDm+1bgGcPKi5JkiRJkiRNvmFN/C1JkiRJkqRZxCSTJEmSJEmS+maSSZIkSZIkSX0zySRJkiRJkqS+mWSSJEmSJElS30wySZIkSZIkqW8mmSRJkiRJktQ3k0ySJEmSJEnqm0kmSZIkSZIk9c0kkyRJkiRJkvpmkkmSJEmSJEl9G1iSKcnpSe5Mcl1b2d8mWZnkquZ1aJdzD05yY5Kbk5w0qBglSZIkSZI0OQbZk+kM4OAO5R+oqr2b1wXjDyaZA3wIOATYEzg6yZ4DjFOSJEmSJEl9GliSqaq+CdyzEafuC9xcVbdU1cPAZ4HDJzU4SZIkSZIkTaphzMn0+iTXNMPptulwfAFwW9v+iqasoySLk1ye5PK77rprsmOVJEmSJElSD6Y6yfQR4GnA3sDtwD92qJMOZdXtglW1pKoWVdWi+fPnT06UkiRJkiRJ2iDrTTIleXqSi8Ym8E7yrCT/fWNuVlV3VNW6qnoU+BdaQ+PGWwHs1La/I7BqY+4nSZIkSZKkqdFLT6Z/AU4GHgGoqmuAozbmZkm2b9v9PeC6DtUuA3ZPsluSzZp7nb8x95MkSZIkSdLUmNtDncdV1XeTx4xiW7u+k5KcBRwAPCnJCuAU4IAke9Ma/nYr8GdN3R2Aj1fVoVW1NsnrgaXAHOD0qrq+948kSZIkSZKkqdZLkunuJE+jmRcpyZG05lOaUFUd3aH4E13qrgIObdu/ALigh9gkSZIkSZI0DfSSZDoBWALskWQl8CPglQONSpIkSZIkSTPKhEmmJJsAi6rqpUnmAZtU1QNTE5okSZIkSZJmigkn/m5WgXt9s/1zE0ySJEmSJEnqpJfV5ZYleWuSnZJsO/YaeGSSJEmSJEmaMXqZk+m1zfsJbWUFPHXyw5EkSZIkSdJMtN4kU1XtNhWBSJIkSZIkaeZab5IpyabAnwMvbIouBj5WVY8MMC5JkiRJkiTNIL0Ml/sIsCnw4Wb/mKbsdYMKSpIkSZIkSTNLL0mm36yqZ7ftfy3J1YMKSJIkSZIkSTNPL6vLrUvytLGdJE8F1g0uJEmSJEmSJM00vfRkOhH4epJbgAC7AK8ZaFSSJEmSJEmaUXpZXe6iJLsDC2klmb5fVQ+t77wkpwOHAXdW1V5N2anAfwMeBn4IvKaqVnc491bgAVo9ptZW1aKeP5EkSZIkSZKm3HqHyyU5Adiiqq6pqquBxyX5ix6ufQZw8LiyZcBeVfUs4AfAyROc/6Kq2tsEkyRJkiRJ0vTXy5xMf9re26iq7gX+dH0nVdU3gXvGlV1YVWub3e8AO25ArJIkSZIkSZqmekkybZIkYztJ5gCbTcK9Xwt8pcuxAi5MckWSxZNwL0mSJEmSJA1QLxN/LwU+l+SjtJI/xwNf7eemSd4BrAU+3aXK/lW1Ksl2wLIk3296RnW61mJgMcDOO+/cT1iSJEmSJEnaSL30ZHobcBHw58AJzfZfb+wNkxxLa0LwV1ZVdapTVaua9zuBc4F9u12vqpZU1aKqWjR//vyNDUuSJEmSJEl96GV1uUeBjwIfTbItsGNVrduYmyU5mFbS6neq6sEudeYBm1TVA832gcC7NuZ+kiRJkiRJmhq9rC53cZLHNwmmq4BPJnl/D+edBXwbWJhkRZLjgNOArWgNgbuqGYJHkh2SXNCc+mTgW0muBr4LfLmq+hqeJ0mSJEmSpMHqZU6mJ1TV/UleB3yyqk5Jcs36TqqqozsUf6JL3VXAoc32LcCze4hLkiRJkiRJ00QvczLNTbI98EfAlwYcjyRJkiRJkmagXnoyvYvWCnPfqqrLkjwVuGmwYUmSpKly3pUrOXXpjaxavYYdtt6CEw9ayBH7LBh2WJIkSZphepn4+/PA59v2bwH+YJBBSZKkqXHelSs5+ZxrWfNIa02PlavXcPI51wKYaJIkSdIG6WW4nCRJmqVOXXrjLxJMY9Y8so5Tl944pIgkSZI0U/UyXE7SLOUQGUmrVq/ZoHJJkiSpG3sySSNqbIjMytVrKH45ROa8K1cOOzRJU2iHrbfYoHJJkiSpm/UmmZJsnuSPk7w9yTvHXlMRnKTBcYiMJIATD1rIFpvOeUzZFpvO4cSDFg4pIkmSJM1UvQyX+3fgPuAK4KHBhiNpqjhERhL8cnLvN599FQALHDorSZKkjdRLkmnHqjp44JFImlI7bL0FKzsklBwiI42eI/ZZ8Isk0yUnvXjI0UiSJGmm6mVOpv9M8hsDj0TSlHKIjCRJkiRpMvXSk+m3gVcn+RGt4XIBqqqeNdDIJA3U2FCYt3z+atY9Wmy31ea8/dBnOERGkiRJkrRRekkyHTLwKCQNxRH7LOCDF93Ej+7+OZ9dvB9Pnb/lsEOSJEmSJM1Q6x0uV1U/rqofA2uAanutV5LTk9yZ5Lq2sm2TLEtyU/O+TZdzj23q3JTk2N4+jiRJkiRJkoZhvUmmJC9PchPwI+AbwK3AV3q8/hnA+EnDTwIuqqrdgYua/fH33BY4BXgesC9wSrdklCRJkobnvCtXsv97v8ZuJ32Z/d/7Nc67cuWwQ5IkSUPSy8Tf7wb2A35QVbsBLwEu6eXiVfVN4J5xxYcDZzbbZwJHdDj1IGBZVd1TVfcCy/jVZJWkSdRT90RJktqcd+VKTj7nWlauXkMBK1ev4eRzrjXRJEnSiOolyfRIVf0U2CTJJlX1dWDvPu755Kq6HaB5365DnQXAbW37K5qyX5FkcZLLk1x+11139RGWJEmSNsSpS29kzSPrHlO25pF1nLr0xiFFJEmjw56kmo56mfh7dZItgW8Cn05yJ7B2sGGRDmUdO1pU1RJgCcCiRYvsjCFJkjRFVq1es0HlkqTJMdaTdCzRP9aTFHC1aA1VLz2ZDgceBP4S+CrwQ+C/9XHPO5JsD9C839mhzgpgp7b9HYFVfdxTkiRJk2yHrbfYoHJJ0uSwJ6mmq16STNsBm1XV2qo6E/gXYKs+7nk+MLZa3LHAv3eosxQ4MMk2zYTfBzZlkiRJmiZOPGghW2w65zFlW2w6hxMPWjikiCRpNNiTVNNVL0mmzwOPtu2va8rWK8lZwLeBhUlWJDkOeC/wsmbFupc1+yRZlOTjAFV1D60Jxy9rXu9qyiRNsk5jUyVJ6sUR+yzgH37/N36xv2DrLfiH3/8Nh2pI0oDZk1TTVS9zMs2tqofHdqrq4SSb9XLxqjq6y6GXdKh7OfC6tv3TgdN7uY8kSZKG44h9FvDms68C4JKTXjzkaCRpNJx40MLHzMkE9iTV9NBLT6a7krx8bCfJ4cDdgwtJkiRJkiR1Y09STVe9JJmOB96e5P8luQ14G/Bngw1L0lQr12aUJEmSZoz2hNIlJ73YBJOmhfUOl6uqHwL7JdkSSFU9MPiwJEmSJEmSNJOstydTkjcleTzwc+ADSZYnOXDwoUmSJEmSJGmm6GW43Gur6n7gQGA74DU0K8JJmgVcXk6SJEmSNAl6STKNfQU9FPhkVV2NX0slSZIkSZLUppck0xVJLqSVZFqaZCvg0cGGJUmSJEmSpJlkvRN/A8cBewO3VNWDSZ5Ia8icJEmSJEmSBPS2utyjwPK2/Z8CPx1kUJIkSZIkSZpZehkuJ2kk1LADkCRJkiTNYF2TTEl2m8pAJEmSJEmSNHNN1JPpCwBJLprMGyZZmOSqttf9Sd48rs4BSe5rq/POyYxBkiRJkiRJk2uiOZk2SXIK8PQkfzX+YFW9f2NuWFU30ppInCRzgJXAuR2q/kdVHbYx95DUuww7AEmSJEnSrDBRT6ajgP+ilYjaqsNrMrwE+GFV/XiSridJkiRJkqQh6NqTqelx9L4k11TVVwZ0/6OAs7oce36Sq4FVwFur6voBxSBJkiRJkqQ+dU0yJXlVVf0bsGeSZ4w/vrHD5dquvxnwcuDkDoeXA7tU1c+SHAqcB+ze5TqLgcUAO++8cz8hSZIkSZIkaSNNNFxuXvO+Jb86VG7LSbj3IcDyqrpj/IGqur+qftZsXwBsmuRJnS5SVUuqalFVLZo/f/4khCVJkiRJkqQNNdFwuY81m/+3qi5pP5Zk/0m499F0GSqX5CnAHVVVSfallQz76STcU1IXVcOOQJIkSZI0k03Uk2nMP/dY1rMkjwNeBpzTVnZ8kuOb3SOB65o5mf4JOKrKr8CSJEmSJEnT1URzMj0f+C1gfpK/ajv0eGBOPzetqgeBJ44r+2jb9mnAaf3cQ5IkSZIkSVOna5IJ2IzW3Etzac3DNOZ+Wj2NJM0CSYYdgiRJkiRpFphoTqZvAN9IckZV/TjJVq3i1oTckiRJkiRJ0piJejKN2SrJlcC2AEnuBo6tqusGGpkkSZIkSZJmjF4m/l4C/FVV7VJVuwBvacokzSLOrC9JkiRJ6kcvSaZ5VfX1sZ2quhiYN7CIJEmSJEmSNOP0MlzuliR/A3yq2X8V8KPBhSRJkiRJkqSZppeeTK8F5gPnAOc2268ZZFCSJEmSJEmaWdbbk6mq7gXeOAWxSJIkSZIkaYbqmmRKcv5EJ1bVyyc/HElTLcMOQJIkSZI0K0zUk+n5wG3AWcCl+F1UkiRJkiRJXUyUZHoK8DLgaOCPgS8DZ1XV9VMRmCRJkiRJkmaOrhN/V9W6qvpqVR0L7AfcDFyc5A1TFp2kKVM17AgkSZIkSTPZhBN/J9kc+F1avZl2Bf6J1ipzfUtyK/AAsA5YW1WLxh0P8EHgUOBB4NVVtXwy7i1Jkn6pzDJLkiRpEkw08feZwF7AV4C/q6rrBnD/F1XV3V2OHQLs3ryeB3ykeZckSZIkSdI0M1FPpmOAnwNPB97Y6lgEtCYAr6p6/IBjOxz412r9efU7SbZOsn1V3T7g+0ojJU7pL408OzJJkiRpMnRNMlVV1/maJkkBFyYp4GNVtWTc8QW0Vrcbs6Ipe0ySKcliYDHAzjvvPLhoJUmapcwxSZIkaTIMOpE0kf2r6jm0hsWdkOSF44536l/xK78HV9WSqlpUVYvmz58/iDglSZIkSZK0HkNLMlXVqub9TuBcYN9xVVYAO7Xt7wismpropNFT9mWQRpYTf0uSJGkyDCXJlGRekq3GtoEDgfETi58P/Ela9gPucz4mSZIkSZKk6Wmiib8H6cnAuc1k4nOBz1TVV5McD1BVHwUuAA4FbgYeBF4zpFilkWBHBml0+eMvSZKkyTCUJFNV3QI8u0P5R9u2CzhhKuOSJGkUmWSWJEnSZBjmxN+SphG/ZEqSJEmS+mGSSRpx6biQo6RR4sT/kiRJmgwmmSQBfsmUJEmSJPXHJJMkSSPO4bKSJEmaDCaZJAF+yZQkSZIk9cckkyRJkiRJkvpmkkmSpBFnT0ZJkiRNBpNMkiRJkiRJ6ptJJkmAPRmkUebqkpIkSZoMJpmkEZcMOwJJw2aSWZIkSZPBJJMkwJ4MkiRJkqT+THmSKclOSb6e5IYk1yd5U4c6ByS5L8lVzeudUx2nJEmjwhSzJEmSJsPcIdxzLfCWqlqeZCvgiiTLqup74+r9R1UdNoT4pJHkcBlJkiRJUj+mvCdTVd1eVcub7QeAG4AFUx2HJElqKbPMkiRJmgRDnZMpya7APsClHQ4/P8nVSb6S5JkTXGNxksuTXH7XXXcNKFJp9vMrpjS6/PmXJEnSZBhakinJlsAXgTdX1f3jDi8HdqmqZwP/DJzX7TpVtaSqFlXVovnz5w8uYEmSJEmSJHU1lCRTkk1pJZg+XVXnjD9eVfdX1c+a7QuATZM8aYrDlEaKw2Wk0eWPvyRJkibDMFaXC/AJ4Iaqen+XOk9p6pFkX1px/nTqopQkSZIkSdKGGMbqcvsDxwDXJrmqKXs7sDNAVX0UOBL48yRrgTXAUWU3C2mg/AHTbHHelSs5demNrFq9hh223oITD1rIEfu4vsSEfABIkiRpEkx5kqmqvgVkPXVOA06bmogkSbPFeVeu5ORzrmXNI+sAWLl6DSefcy2AiaYJlFkmSZIkTYKhri4nafqwr6Bmg1OX3viLBNOYNY+s49SlNw4pIkmSJGl0mGSSJM0aq1av2aBytZhkliRJ0mQwySSp4bdMzXw7bL3FBpVLkiRJmjwmmaQR1yzkKM0KJx60kC02nfOYsi02ncOJBy0cUkQzgylmSZIkTYZhrC4naRpyuIxmg7HJvd/2xWt4aO2jPHHeZvzNYXs66fd6uICrtGFcxVKSpM7sySRJmlWO2GcBv7nrtgB84BV7+8VP0qQaW8Vy5eo1FL9cxfK8K1cOOzRJkobOJJMkwOEy0ijz51/qnatYSpLUnUkmSZIkqUeuYilJUncmmSQBzskkjTJ//qXeuYqlJEndmWSSJM06Lpq4YcoBc1LPXMVSkqTuXF1OEuDqUpIk9WJsMYE3n30VAAtcXU6SpF8YSk+mJAcnuTHJzUlO6nB88yRnN8cvTbLr1EcpjQY7fEiyI5O0YdoTSpec9GITTJIkNaY8yZRkDvAh4BBgT+DoJHuOq3YccG9V/TrwAeB9UxulNHr8jilJkiRJ6scwejLtC9xcVbdU1cPAZ4HDx9U5HDiz2f4C8JLEGTYkSRoEk8ySJEmaDMNIMi0AbmvbX9GUdaxTVWuB+4AnTkl00ohySibNRjZrSZIkaepkqif7TfKHwEFV9bpm/xhg36p6Q1ud65s6K5r9HzZ1ftrheouBxc3uQuDGAX+EqfAk4O5hB6Fpy/ahbmwb6sa2oYnYPtSNbUPd2DY0EdvH7LRLVc1fX6VhrC63AtipbX9HYFWXOiuSzAWeANzT6WJVtQRYMoA4hybJ5VW1aNhxaHqyfagb24a6sW1oIrYPdWPbUDe2DU3E9jHahjFc7jJg9yS7JdkMOAo4f1yd84Fjm+0jga+V66tLkiRJkiRNW1Pek6mq1iZ5PbAUmAOcXlXXJ3kXcHlVnQ98AvhUkptp9WA6aqrjlCRJkiRJUu+GMVyOqroAuGBc2Tvbtv8L+MOpjmsamVXD/zTpbB/qxrahbmwbmojtQ93YNtSNbUMTsX2MsCmf+FuSJEmSJEmzzzDmZJIkSZIkSdIsY5JpmklycJIbk9yc5KRhx6OplWSnJF9PckOS65O8qSnfNsmyJDc179s05UnyT017uSbJc4b7CTRoSeYkuTLJl5r93ZJc2rSNs5sFFUiyebN/c3N812HGrcFLsnWSLyT5fvMMeb7PDgEk+cvm35TrkpyV5Nd8doyuJKcnuTPJdW1lG/ysSHJsU/+mJMd2updmli5t49Tm35VrkpybZOu2Yyc3bePGJAe1lft9Zpbp1Dbajr01SSV5UrPvc2PEmWSaRpLMAT4EHALsCRydZM/hRqUpthZ4S1U9A9gPOKFpAycBF1XV7sBFzT602sruzWsx8JGpD1lT7E3ADW377wM+0LSNe4HjmvLjgHur6teBDzT1NLt9EPhqVe0BPJtWO/HZMeKSLADeCCyqqr1oLbpyFD47RtkZwMHjyjboWZFkW+AU4HnAvsApY4kpzWhn8KttYxmwV1U9C/gBcDJA8/vpUcAzm3M+3PwhzO8zs9MZ/GrbIMlOwMuA/9dW7HNjxJlkml72BW6uqluq6mHgs8DhQ45JU6iqbq+q5c32A7S+JC6g1Q7ObKqdCRzRbB8O/Gu1fAfYOsn2Uxy2pkiSHYHfBT7e7Ad4MfCFpsr4tjHWZr4AvKSpr1koyeOBF9JanZWqeriqVuOzQy1zgS2SzAUeB9yOz46RVVXfpLV6c7sNfVYcBCyrqnuq6l5aiYhf+QKqmaVT26iqC6tqbbP7HWDHZvtw4LNV9VBV/Qi4mdZ3Gb/PzEJdnhvQ+mPEXwPtEz373BhxJpmmlwXAbW37K5oyjaBmiMI+wKXAk6vqdmglooDtmmq2mdHyv2n9Q/5os/9EYHXbL3/t//9/0Taa4/c19TU7PRW4C/hkM5ywnNwJAAAGqklEQVTy40nm4bNj5FXVSuB/0for8+20ngVX4LNDj7WhzwqfIaPptcBXmm3bxohL8nJgZVVdPe6QbWPEmWSaXjr9pdDl/0ZQki2BLwJvrqr7J6raocw2MwslOQy4s6quaC/uULV6OKbZZy7wHOAjVbUP8HN+OdylE9vHiGiGIhwO7AbsAMyjNZRhPJ8d6qRbe7CdjJgk76A1rcOnx4o6VLNtjIgkjwPeAbyz0+EOZbaNEWKSaXpZAezUtr8jsGpIsWhIkmxKK8H06ao6pym+Y2woS/N+Z1Numxkd+wMvT3Irra7nL6bVs2nrZggMPPb//y/aRnP8CXTu5qzZYQWwoqoubfa/QCvp5LNDLwV+VFV3VdUjwDnAb+GzQ4+1oc8KnyEjpJmg+TDglVU1lhSwbYy2p9H648XVze+mOwLLkzwF28bIM8k0vVwG7N6s+LIZrcn0zh9yTJpCzbwXnwBuqKr3tx06HxhbgeFY4N/byv+kWcVhP+C+se7uml2q6uSq2rGqdqX1bPhaVb0S+DpwZFNtfNsYazNHNvX9a9EsVVU/AW5LsrApegnwPXx2qDVMbr8kj2v+jRlrGz471G5DnxVLgQOTbNP0ljuwKdMsk+Rg4G3Ay6vqwbZD5wNHpbUi5W60Jnn+Ln6fGQlVdW1VbVdVuza/m64AntP8PuJzY8TNXX8VTZWqWpvk9bR+2OYAp1fV9UMOS1Nrf+AY4NokVzVlbwfeC3wuyXG0vjD8YXPsAuBQWpMtPgi8ZmrD1TTwNuCzSd4DXEkz8XPz/qkkN9PqhXDUkOLT1HkD8Onml/pbaD0PNsFnx0irqkuTfAFYTmuoy5XAEuDL+OwYSUnOAg4AnpRkBa3Vnjbo94yquifJu2klFADeVVX2eJvhurSNk4HNgWXNGgDfqarjq+r6JJ+jlbReC5xQVeua6/h9Zpbp1Daq6hNdqvvcGHHxj1OSJEmSJEnql8PlJEmSJEmS1DeTTJIkSZIkSeqbSSZJkiRJkiT1zSSTJEmSJEmS+maSSZIkSZIkSX0zySRJkma9JO9Icn2Sa5JcleR5w46pH0kuTrJo2HFIkiS1mzvsACRJkgYpyfOBw4DnVNVDSZ4EbDbksCRJkmYdezJJkqTZbnvg7qp6CKCq7q6qVQBJnpvkG0muSLI0yfZt5Vcn+XaSU5Nc15S/OslpYxdO8qUkBzTbBzb1lyf5fJItm/Jbk/xdU35tkj2a8i2TfLIpuybJH0x0nQ5eleQ/k1yXZN/m3H2bsiub94VN+TOTfLfpxXVNkt2b8le1lX8syZxJ/m8vSZJGiEkmSZI0210I7JTkB0k+nOR3AJJsCvwzcGRVPRc4Hfj75pxPAm+squf3coOmd9R/B15aVc8BLgf+qq3K3U35R4C3NmV/A9xXVb9RVc8CvtbDddrNq6rfAv6iiR3g+8ALq2of4J3A/2jKjwc+WFV7A4uAFUmeAbwC2L8pXwe8spfPK0mS1InD5SRJ0qxWVT9L8lzgBcCLgLOTnEQrgbMXsCwJwBzg9iRPALauqm80l/gUcMh6brMfsCdwSXOtzYBvtx0/p3m/Avj9ZvulwFFtcd6b5LD1XKfdWc1530zy+CRbA1sBZzY9lQrYtKn7beAdSXYEzqmqm5K8BHgucFlzry2AO9fzOSVJkroyySRJkma9qloHXAxcnORa4FhaCZ/rx/dWapI11eVSa3lsT/BfGzsNWFZVR3c576HmfR2//P0rHe6zvuu0G39uAe8Gvl5Vv5dkV1qfmar6TJJLgd8FliZ5XXOvM6vq5B7uJUmStF4Ol5MkSbNakoVjcxA19gZ+DNwIzG8mBifJpkmeWVWrgfuS/HZTv30I2a3A3kk2SbITsG9T/h1g/yS/3lzrcUmevp7QLgRe3xbnNht4nVc0dX6b1rC7+4AnACub469uu/ZTgVuq6p+A84FnARcBRybZrqmzbZJd1hOzJElSVyaZJEnSbLclrSFk30tyDa3haH9bVQ8DRwLvS3I1cBXwW805rwE+lOTbwJq2a10C/Ai4FvhfwHKAqrqLVlLnrOYe3wH2WE9c7wG2aSbuvhp40QZe594k/wl8FDiuKfufwD8kuYTW8L8xrwCuS3JVc71/rarv0Zr/6cLmXstoTZIuSZK0UVLVrTe4JEmSmmFnX6qqvYYciiRJ0rRmTyZJkiRJkiT1zZ5MkiRJkiRJ6ps9mSRJkiRJktQ3k0ySJEmSJEnqm0kmSZIkSZIk9c0kkyRJkiRJkvpmkkmSJEmSJEl9M8kkSZIkSZKkvv1/7hCPqktrutUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,3))\n",
    "plt.plot(neg_motif_scores, \"-o\")\n",
    "plt.xlabel(\"Sequence base\")\n",
    "plt.ylabel(\"Motif scan score\")\n",
    "plt.ylim(0, 20)  \n",
    "plt.title(\"Negative example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYLxiOEShfbP"
   },
   "source": [
    "The motif scan yields a group of three high-scoring motif alignment positions at a fixed distance near the center of the sequence in the positive example. The spacing of the high-scoring motif alignments is random in the negative sequence. \n",
    "\n",
    "Note: If you find that your negative example is too close to the positive examle (i.e. the randomly spaced motifs happen to have a spacing close to the positive example, feel free to provide another index value to select a different negative). \n",
    "\n",
    "For example, you can change the code to select a negative example to the below: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "neg_indx=np.flatnonzero(simulation_data.y_valid==0)[2]\n",
    "print(neg_indx)\n",
    "neg_X=simulation_data.X_valid[neg_indx:neg_indx+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCfzueaWhfbQ"
   },
   "source": [
    "### In silico mutagenesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAxE_amLhfbQ"
   },
   "source": [
    "To determine how much each position in the input sequence contrinbutes to the model's prediction, we can perform saturation mutagenesis on the sequence. For each position in the input sequence, we introduce each of the four possible bases A, C, G, T and quantify the effect on the model's predictions.\n",
    "\n",
    "\n",
    "TODO: Explain what ISM is doing, equation from dragonn code. \n",
    "TODO: Update ISM to reflect the difference of logits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.interpret.ism import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=get_logit(multi_filter_keras_model,simulation_data.X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=multi_filter_keras_model\n",
    "X=simulation_data.X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"ism.inputs.pkl\",'wb') as f: \n",
    "    pickle.dump([model,X],f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-LN7IlUhfbQ"
   },
   "outputs": [],
   "source": [
    "from dragonn.tutorial_utils import in_silico_mutagenesis, plot_ism\n",
    "ism_pos=in_silico_mutagenesis(multi_filter_keras_model,pos_X)\n",
    "ism_neg=in_silico_mutagenesis(multi_filter_keras_model,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6Vya1NBhfbT",
    "outputId": "2c29d553-077c-40c0-9301-84e60547642b"
   },
   "outputs": [],
   "source": [
    "# create discrete colormap of ISM scores \n",
    "from dragonn.tutorial_utils import plot_ism\n",
    "plot_ism(ism_pos,\"Positive Example\")\n",
    "plot_ism(ism_neg,\"Negative Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LElrqg4hhfbX"
   },
   "source": [
    "### Gradient x Input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sToN6KaqhfbX"
   },
   "source": [
    "Consider a neural net being a function: $f(x_1, ..., x_N; w) = y$\n",
    "\n",
    "One way to tell whether the input feature is important is to compute the gradient of the function with respect to (w.r.t.) model input: $\\frac{\\partial f}{\\partial x_i}$\n",
    "\n",
    "This approach is called saliency maps: \"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\", by Karen Simonyan, Andrea Vedaldi and Andrew Zisserma https://arxiv.org/pdf/1312.6034.pdf\n",
    "\n",
    "In genomics, we typically visualize only gradients for bases observed in the sequence (called input masked gradients or input*grad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uccouP4GhfbY"
   },
   "outputs": [],
   "source": [
    "from dragonn.tutorial_utils import  input_grad,plot_seq_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Muro8H0Ahfba"
   },
   "outputs": [],
   "source": [
    "gradinput_pos=input_grad(multi_filter_keras_model,pos_X)\n",
    "gradinput_neg=input_grad(multi_filter_keras_model,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p64eg1Ghfbb",
    "outputId": "113f6a69-a5d1-4813-803b-47b6011ab2fa"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(gradinput_pos,pos_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyt3Jn5Dhfbd",
    "outputId": "c5430d1f-a46f-4909-d3db-b8f03f5e53e9"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(gradinput_neg,neg_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1_eQsEshfbg"
   },
   "source": [
    "Let's zoom in to the center 150 bp of the sequence, where the simulated homotypic motif grammar is to be found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VbnG8C6hfbg",
    "outputId": "2244146a-4d85-4952-b2be-70bef8ef4b87"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(gradinput_pos,pos_X,xlim=(675,825))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cfYBSCg_hfbj",
    "outputId": "5587cd9d-bdc2-49cb-dd40-c0ea3cda44f6"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(gradinput_neg,neg_X,xlim=(675,825))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Votf6uXthfbl"
   },
   "source": [
    "### DeepLIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-V9EmMqhfbl"
   },
   "source": [
    "[DeepLIFT](https://arxiv.org/pdf/1605.01713v2.pdf) allows us to obtain scores for specific sequence indicating the importance of each position in the sequence. DeepLIFT can accept a custom reference. For our purposes, we provide a 40% GC reference. \n",
    "\n",
    "\n",
    "TODO: use a dinucleotide-shuffled reference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoCK-8obhfbn"
   },
   "outputs": [],
   "source": [
    "from dragonn.tutorial_utils import deeplift\n",
    "\n",
    "dl_pos=deeplift(multi_filter_keras_model,pos_X)\n",
    "dl_neg=deeplift(multi_filter_keras_model,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBVn9Gdehfbo",
    "outputId": "5eb935c9-19bb-4326-a127-dd10fc04bd82"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(dl_pos,pos_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUdrsFoEhfbq",
    "outputId": "7635dd4f-0492-4e75-fb56-a0824052cf77"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(dl_neg,neg_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gauKpa1Lhfbr"
   },
   "source": [
    "Zooming in to the 150 bases at the center of the sequence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xq_FrkaYhfbs",
    "outputId": "6e1a3cf9-f7f4-4172-ddb9-acf9a0c2c11c"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(dl_pos,pos_X,xlim=(675,825))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9KKr-j2hfbv",
    "outputId": "85a9f3ce-90c3-4768-cefe-e2be5ad3ecaf"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(dl_neg,neg_X,xlim=(675,825))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIR0L1BLhfbx"
   },
   "source": [
    "# A multi-layer DragoNN model <a name='9'>\n",
    "\n",
    "<a href=#outline>Home</a> \n",
    "\n",
    "Next, we train a 3 layer model for this task. Will it outperform the single layer model and to what extent will it overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPFsBPq9hfby",
    "outputId": "352bc51b-2ab2-4821-ec50-2aca24b83a63"
   },
   "outputs": [],
   "source": [
    "#Define the model architecture in keras\n",
    "multi_layer_keras_model=Sequential() \n",
    "multi_layer_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "multi_layer_keras_model.add(Activation('relu'))\n",
    "\n",
    "multi_layer_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "multi_layer_keras_model.add(Activation('relu'))\n",
    "\n",
    "multi_layer_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "multi_layer_keras_model.add(Activation('relu'))\n",
    "multi_layer_keras_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "\n",
    "\n",
    "multi_layer_keras_model.add(Flatten())\n",
    "multi_layer_keras_model.add(Dense(1))\n",
    "multi_layer_keras_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "multi_layer_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')\n",
    "\n",
    "multi_layer_keras_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7iIGEzxIhfb0",
    "outputId": "b7b160d5-08de-4ab7-bb93-15f4bab24d22"
   },
   "outputs": [],
   "source": [
    "## use the keras fit function to train the model for 150 epochs with early stopping after 3 epochs \n",
    "history_multi_layer=multi_layer_keras_model.fit(x=simulation_data.X_train,\n",
    "                                  y=simulation_data.y_train,\n",
    "                                  batch_size=128,\n",
    "                                  epochs=150,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                            History(),\n",
    "                                            metrics_callback],\n",
    "                                  validation_data=(simulation_data.X_valid,\n",
    "                                                   simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouAzZy6jhfb3",
    "outputId": "9fb2e7fe-cef6-4944-f71d-ec5b99c8fa72"
   },
   "outputs": [],
   "source": [
    "## Use the keras predict function to get model predictions on held-out test set. \n",
    "test_predictions=multi_layer_keras_model.predict(simulation_data.X_test)\n",
    "## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "print(ClassificationResult(simulation_data.y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyx11sBGhfb6",
    "outputId": "6350ed00-b511-4477-f4d2-f35b803f3e50"
   },
   "outputs": [],
   "source": [
    "## Visualize the model's performance \n",
    "plot_learning_curve(history_multi_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zERU2ZcVhfb9"
   },
   "outputs": [],
   "source": [
    "ism_pos=in_silico_mutagenesis(multi_layer_keras_model,pos_X)\n",
    "ism_neg=in_silico_mutagenesis(multi_layer_keras_model,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1FaXvrOhfb-",
    "outputId": "e9742031-2212-418a-fbd2-9d7614b9cf8d"
   },
   "outputs": [],
   "source": [
    "# create discrete colormap of ISM scores \n",
    "plot_ism(ism_pos,'Positive Example')\n",
    "plot_ism(ism_neg,'Negative Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrcxhvOshfcA"
   },
   "outputs": [],
   "source": [
    "dl_pos=deeplift(multi_layer_keras_model,pos_X)\n",
    "dl_neg=deeplift(multi_layer_keras_model,neg_X)\n",
    "gradinput_pos=input_grad(multi_layer_keras_model,pos_X)\n",
    "gradinput_neg=input_grad(multi_layer_keras_model,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EekErGBnhfcB",
    "outputId": "440bee98-c45d-4934-88a3-aa72f16ff980"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(gradinput_pos,pos_X)\n",
    "plot_seq_importance(dl_pos,pos_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAKX1vsKhfcD",
    "outputId": "4e6b6b02-967f-4051-b142-5f9a18ca35ed"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(gradinput_neg,neg_X)\n",
    "plot_seq_importance(dl_neg,neg_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RvvOXUzdhfcG"
   },
   "source": [
    "Zooming in to the center of the sequence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPBxWzDUhfcH",
    "outputId": "67379469-d062-45ac-b393-95099e87c419"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(gradinput_pos,pos_X,xlim=(675,825))\n",
    "plot_seq_importance(dl_pos,pos_X,xlim=(675,825))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QQi2N2phfcI",
    "outputId": "9b0abd66-2c8a-4321-9112-9c97f1e72b12"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(gradinput_neg,neg_X,xlim=(675,825))\n",
    "plot_seq_importance(dl_neg,neg_X,xlim=(675,825))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x23gsyx7hfcK"
   },
   "source": [
    "This model performs slightly better than the single layer model but it overfits more. We will try to address that with dropout regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJ_CcYdohfcL"
   },
   "source": [
    "# A regularized multi-layer DragoNN model <a name='10'>\n",
    "    \n",
    "<a href=#outline>Home</a> \n",
    "    \n",
    "Next, we regularize the 3 layer using 0.2 dropout on every convolutional layer. Will dropout improve validation performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6nxUApfhfcL",
    "outputId": "c8bd2899-1a1d-4e99-bbe3-bbeb8d7892bd"
   },
   "outputs": [],
   "source": [
    "#Define the model architecture in keras\n",
    "\n",
    "regularized_keras_model=Sequential() \n",
    "regularized_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "regularized_keras_model.add(Activation('relu'))\n",
    "regularized_keras_model.add(Dropout(0.2))\n",
    "\n",
    "regularized_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "regularized_keras_model.add(Activation('relu'))\n",
    "regularized_keras_model.add(Dropout(0.2))\n",
    "\n",
    "regularized_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "regularized_keras_model.add(Activation('relu'))\n",
    "regularized_keras_model.add(Dropout(0.2))\n",
    "regularized_keras_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "\n",
    "\n",
    "regularized_keras_model.add(Flatten())\n",
    "regularized_keras_model.add(Dense(1))\n",
    "regularized_keras_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "regularized_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')\n",
    "\n",
    "regularized_keras_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NL7Ivww6hfcN",
    "outputId": "56f999df-3763-48f0-8d0e-6bd93e9ac56e"
   },
   "outputs": [],
   "source": [
    "## use the keras fit function to train the model for 150 epochs with early stopping after 3 epochs \n",
    "history_regularized=regularized_keras_model.fit(x=simulation_data.X_train,\n",
    "                                  y=simulation_data.y_train,\n",
    "                                  batch_size=128,\n",
    "                                  epochs=150,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                            History(),\n",
    "                                            metrics_callback],\n",
    "                                  validation_data=(simulation_data.X_valid,\n",
    "                                                   simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NB0ockF6hfcQ",
    "outputId": "eec6ec5c-a71c-43dc-d9f1-77814c435ae5"
   },
   "outputs": [],
   "source": [
    "## Use the keras predict function to get model predictions on held-out test set. \n",
    "test_predictions=regularized_keras_model.predict(simulation_data.X_test)\n",
    "## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "print(ClassificationResult(simulation_data.y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4LBbu66hfcS",
    "outputId": "c3973581-7217-4ad1-e719-bcb941009bed"
   },
   "outputs": [],
   "source": [
    "## Visualize the model's performance \n",
    "plot_learning_curve(history_regularized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nf8HfopyhfcT"
   },
   "outputs": [],
   "source": [
    "ism_pos=in_silico_mutagenesis(regularized_keras_model,pos_X)\n",
    "ism_neg=in_silico_mutagenesis(regularized_keras_model,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gI465jf0hfcT",
    "outputId": "81ac3257-440e-4381-e005-dc29c647a68e"
   },
   "outputs": [],
   "source": [
    "plot_ism(ism_pos,'Positive Example')\n",
    "plot_ism(ism_neg,'Negative Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qCjBNc0hfcU"
   },
   "outputs": [],
   "source": [
    "dl_pos=deeplift(regularized_keras_model,pos_X)\n",
    "dl_neg=deeplift(regularized_keras_model,neg_X)\n",
    "gradinput_pos=input_grad(regularized_keras_model,pos_X).squeeze()\n",
    "gradinput_neg=input_grad(regularized_keras_model,neg_X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fynr-X0BhfcW",
    "outputId": "af880544-0955-4b66-cba0-eda5fdfcb5a6"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(gradinput_pos,pos_X)\n",
    "plot_seq_importance(dl_pos,pos_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peYZjh9AhfcX",
    "outputId": "a93a189a-28ca-4d12-c7e9-c3356293c66a"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(gradinput_neg,neg_X)\n",
    "plot_seq_importance(dl_neg,neg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAjGXKaFhfcZ",
    "outputId": "c10c7866-f679-4227-c924-7391598e2e64"
   },
   "outputs": [],
   "source": [
    "print(\"Positive:\")\n",
    "plot_seq_importance(gradinput_pos,pos_X,xlim=(675,825))\n",
    "plot_seq_importance(dl_pos,pos_X,xlim=(675,825))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVhT6AmGhfca",
    "outputId": "f217cfa1-0ac7-46ec-e4fe-367d347eeb57"
   },
   "outputs": [],
   "source": [
    "print(\"Negative:\")\n",
    "plot_seq_importance(gradinput_neg,neg_X,xlim=(675,825))\n",
    "plot_seq_importance(dl_neg,neg_X,xlim=(675,825))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2vhSeq9hfcc"
   },
   "source": [
    "As expected, dropout decreased the overfitting this model displayed previously and increased test performance. Let's see the learned filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wb3JF6P7hfcc"
   },
   "source": [
    "### Saving a keras model \n",
    "\n",
    "\n",
    "We save the optimal regularized multi-layer keras model to an hdf5 file that contains both the model weights and architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fC6LG-Ewhfcc"
   },
   "outputs": [],
   "source": [
    "regularized_keras_model.save(\"TAL1.Simulation.Regularized.3ConvLayers.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdfFZvMThfcd"
   },
   "source": [
    "We can now load the saved model for use in other applications or for further fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7u7UUlLnhfcd"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"TAL1.Simulation.Regularized.3ConvLayers.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-_8RQS7hfce"
   },
   "source": [
    "## Comparison to LSGKM \n",
    "\n",
    "@Av "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ys1cqU5whfce"
   },
   "source": [
    "## For further exploration<a name='11'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRjJ5t00hfce"
   },
   "source": [
    "In this tutorial we explored modeling of homotypic motif density. Other properties of regulatory DNA sequence include\n",
    "![sequence properties 3](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/tutorial_images/sequence_properties_3.jpg?raw=1)\n",
    "![sequence properties 4](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/tutorial_images/sequence_properties_4.jpg?raw=1)\n",
    "\n",
    "DragoNN provides simulations that formulate learning these patterns into classification problems:\n",
    "![sequence](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/tutorial_images/sequence_simulations.png?raw=1)\n",
    "\n",
    "You can view the available simulation functions by running print_available_simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BLPWVdhhfcf",
    "outputId": "7f72989f-6204-4cb2-bd48-042a3971bc52"
   },
   "outputs": [],
   "source": [
    "print_available_simulations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k17hndckhfcg"
   },
   "source": [
    "## Using DragoNN with your own non-simulated data<a name='12'>\n",
    "<a href=#outline>Home</a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PrimerTutorial 1 - Exploring model architectures for a homotypic motif density simulation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
